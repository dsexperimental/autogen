{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Group Chat\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "This notebook is modified based on https://github.com/microsoft/FLAML/blob/4ea686af5c3e8ff24d9076a7a626c8b28ab5b1d7/notebook/autogen_multiagent_roleplay_chat.ipynb\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install pyautogen~=0.2.0b4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed current working directory to 'c:\\Dave\\dev\\ext_projects\\autogen'\n"
     ]
    }
   ],
   "source": [
    "## BOCK INSERTED TO SET PROPER WORKING DIRECTORY (WORKSPACE DIRECTORY)\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Find the .venv directory in sys.path\n",
    "venv_path = next((p for p in sys.path if '.venv' in p), None)\n",
    "\n",
    "if venv_path:\n",
    "    # Calculate the parent directory of the .venv path\n",
    "    workspace_dir = os.path.dirname(venv_path)\n",
    "\n",
    "    # Add the parent directory to sys.path if not already included\n",
    "    if workspace_dir not in sys.path:\n",
    "        sys.path.append(workspace_dir)\n",
    "        print(f\"Added '{workspace_dir}' to sys.path\")\n",
    "\n",
    "    # Change the current working directory to the workspace directory\n",
    "    os.chdir(workspace_dir)\n",
    "    print(f\"Changed current working directory to '{workspace_dir}'\")\n",
    "else:\n",
    "    print(\"Virtual environment path not found in sys.path\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "config_list_gpt4 = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    filter_dict={\"model\": [\"gpt-4-1106-preview\"]},\n",
    "    #filter_dict={\"model\": [\"gpt-3.5-turbo-16k\"]}\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the gpt-4 models are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "You can set the value of config_list in any way you prefer. Please refer to this [notebook](https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb) for full code examples of the different methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"config_list\": config_list_gpt4, \"cache_seed\": 43}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "   name=\"User_proxy\",\n",
    "   system_message=\"A human admin.\",\n",
    "   code_execution_config={\n",
    "       \"last_n_messages\": 2, \n",
    "       \"work_dir\": \"groupchat\",\n",
    "       \"use_docker\": \"base-chat-app:latest\"\n",
    "   },\n",
    "   human_input_mode=\"ALWAYS\"\n",
    ")\n",
    "coder = autogen.AssistantAgent(\n",
    "    name=\"Coder\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "pm = autogen.AssistantAgent(\n",
    "    name=\"Product_manager\",\n",
    "    system_message=\"Creative in software product ideas.\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, coder, pm], messages=[], max_round=12)\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "To find the latest paper about GPT-4 on arXiv, we can use the arXiv API to search for papers that mention \"GPT-4\" in their metadata. I will write a Python script that queries the arXiv API for the latest papers on GPT-4 and prints out the title, authors, summary, and publication date of the most recent one. After we have the information about the paper, I can analyze the summary to identify potential applications in software.\n",
      "\n",
      "Let's start with the Python script to query the arXiv API:\n",
      "\n",
      "```python\n",
      "# filename: arxiv_gpt4_search.py\n",
      "import urllib.request\n",
      "import urllib.parse\n",
      "import feedparser\n",
      "\n",
      "# Base API query URL\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "\n",
      "# Search parameters\n",
      "search_query = 'all:gpt-4'  # search for the term 'gpt-4' in all fields\n",
      "start = 0                     # start at the first result\n",
      "max_results = 1               # want only the most recent result\n",
      "\n",
      "query = f'search_query={search_query}&start={start}&max_results={max_results}&sortBy=submittedDate&sortOrder=descending'\n",
      "url = base_url + query\n",
      "\n",
      "# Perform the query\n",
      "with urllib.request.urlopen(url) as response:\n",
      "    response_text = response.read()\n",
      "\n",
      "# Parse the response using feedparser\n",
      "feed = feedparser.parse(response_text)\n",
      "\n",
      "# Print out the information of the latest paper\n",
      "if feed.entries:\n",
      "    entry = feed.entries[0]\n",
      "    print(f\"Title: {entry.title}\")\n",
      "    print(f\"Authors: {', '.join(author.name for author in entry.authors)}\")\n",
      "    print(f\"Published: {entry.published}\")\n",
      "    print(f\"Summary: {entry.summary}\")\n",
      "else:\n",
      "    print(\"No papers found on GPT-4.\")\n",
      "```\n",
      "\n",
      "Please save the above script as `arxiv_gpt4_search.py` and run it. After we get the information about the latest paper, I will help you identify its potential applications in software based on the summary provided.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"arxiv_gpt4_search.py\", line 4, in <module>\n",
      "    import feedparser\n",
      "ModuleNotFoundError: No module named 'feedparser'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "The error indicates that the `feedparser` module is not installed on your system. We need to install this module before we can run the script. You can install `feedparser` using `pip`, which is the package installer for Python.\n",
      "\n",
      "Please run the following command to install the `feedparser` module:\n",
      "\n",
      "```sh\n",
      "pip install feedparser\n",
      "```\n",
      "\n",
      "After installing `feedparser`, please try running the `arxiv_gpt4_search.py` script again. If you encounter any further issues, please let me know.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Collecting feedparser\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.1/81.1 kB 407.5 kB/s eta 0:00:00\n",
      "Collecting sgmllib3k (from feedparser)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: sgmllib3k\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=f841ead580b93c5b5a0378ae903f651de1e3f063b1b4df849a44744cba03b709\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built sgmllib3k\n",
      "Installing collected packages: sgmllib3k, feedparser\n",
      "Successfully installed feedparser-6.0.10 sgmllib3k-1.0.0\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Requirement already satisfied: feedparser in /usr/local/lib/python3.12/site-packages (6.0.10)\n",
      "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/site-packages (from feedparser) (1.0.0)\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "What code should I run now that that is installed?\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCoder\u001b[0m (to chat_manager):\n",
      "\n",
      "Now that the `feedparser` module is installed, you can run the Python script I provided earlier to search for the latest paper about GPT-4 on arXiv. Here is the script again for your convenience:\n",
      "\n",
      "```python\n",
      "# filename: arxiv_gpt4_search.py\n",
      "import urllib.request\n",
      "import urllib.parse\n",
      "import feedparser\n",
      "\n",
      "# Base API query URL\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "\n",
      "# Search parameters\n",
      "search_query = 'all:gpt-4'  # search for the term 'gpt-4' in all fields\n",
      "start = 0                     # start at the first result\n",
      "max_results = 1               # want only the most recent result\n",
      "\n",
      "query = f'search_query={search_query}&start={start}&max_results={max_results}&sortBy=submittedDate&sortOrder=descending'\n",
      "url = base_url + query\n",
      "\n",
      "# Perform the query\n",
      "with urllib.request.urlopen(url) as response:\n",
      "    response_text = response.read()\n",
      "\n",
      "# Parse the response using feedparser\n",
      "feed = feedparser.parse(response_text)\n",
      "\n",
      "# Print out the information of the latest paper\n",
      "if feed.entries:\n",
      "    entry = feed.entries[0]\n",
      "    print(f\"Title: {entry.title}\")\n",
      "    print(f\"Authors: {', '.join(author.name for author in entry.authors)}\")\n",
      "    print(f\"Published: {entry.published}\")\n",
      "    print(f\"Summary: {entry.summary}\")\n",
      "else:\n",
      "    print(\"No papers found on GPT-4.\")\n",
      "```\n",
      "\n",
      "Please save the script as `arxiv_gpt4_search.py` and run it. The script will output the title, authors, publication date, and summary of the most recent paper on GPT-4 from arXiv. Once you have the output, I can help you analyze the summary to identify potential applications in software.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mUser_proxy\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Title: Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural\n",
      "  Scrambled Text\n",
      "Authors: Qi Cao, Takeshi Kojima, Yutaka Matsuo, Yusuke Iwasawa\n",
      "Published: 2023-11-30T18:51:38Z\n",
      "Summary: While Large Language Models (LLMs) have achieved remarkable performance in\n",
      "many tasks, much about their inner workings remains unclear. In this study, we\n",
      "present novel experimental insights into the resilience of LLMs, particularly\n",
      "GPT-4, when subjected to extensive character-level permutations. To investigate\n",
      "this, we first propose the Scrambled Bench, a suite designed to measure the\n",
      "capacity of LLMs to handle scrambled input, in terms of both recovering\n",
      "scrambled sentences and answering questions given scrambled context. The\n",
      "experimental results indicate that most powerful LLMs demonstrate the\n",
      "capability akin to typoglycemia, a phenomenon where humans can understand the\n",
      "meaning of words even when the letters within those words are scrambled, as\n",
      "long as the first and last letters remain in place. More surprisingly, we found\n",
      "that only GPT-4 nearly flawlessly processes inputs with unnatural errors, even\n",
      "under the extreme condition, a task that poses significant challenges for other\n",
      "LLMs and often even for humans. Specifically, GPT-4 can almost perfectly\n",
      "reconstruct the original sentences from scrambled ones, decreasing the edit\n",
      "distance by 95%, even when all letters within each word are entirely scrambled.\n",
      "It is counter-intuitive that LLMs can exhibit such resilience despite severe\n",
      "disruption to input tokenization caused by scrambled text.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mProduct_manager\u001b[0m (to chat_manager):\n",
      "\n",
      "Based on the summary of the paper titled \"Unnatural Error Correction: GPT-4 Can Almost Perfectly Handle Unnatural Scrambled Text,\" we can identify several potential applications in software:\n",
      "\n",
      "1. **Robust Text Processing Systems**: The ability of GPT-4 to handle scrambled text suggests that it could be used to develop more robust text processing systems that are resilient to input errors. This could be particularly useful in applications like data entry systems, where human errors can introduce typos and misspellings.\n",
      "\n",
      "2. **Error Correction Tools**: GPT-4's capability to nearly flawlessly reconstruct original sentences from scrambled ones can be leveraged to create advanced error correction tools. These tools could assist users in correcting typographical errors in documents, emails, and other text-based communications.\n",
      "\n",
      "3. **Accessibility Software**: For individuals with dyslexia or other reading difficulties, software that uses GPT-4 could potentially provide real-time assistance by interpreting and unscrambling text that the user finds challenging to read.\n",
      "\n",
      "4. **Language Learning Applications**: GPT-4 could be integrated into language learning platforms to help learners understand and correct their mistakes. The model's ability to process and correct scrambled text could be used to create exercises that strengthen a learner's grasp of spelling and grammar.\n",
      "\n",
      "5. **Data Cleaning in Machine Learning**: In machine learning projects, data cleaning is a critical step. GPT-4 could be used to preprocess datasets that contain scrambled or corrupted text data, improving the quality of the data fed into other machine learning models.\n",
      "\n",
      "6. **Secure Communication**: The resilience of GPT-4 to scrambled text might be used in secure communication applications where messages are intentionally obfuscated but need to be quickly and accurately deciphered by the intended recipient.\n",
      "\n",
      "7. **Automated Proofreading**: GPT-4 could be employed in automated proofreading tools that not only check for simple spelling mistakes but also for more complex errors that involve scrambled letters within words.\n",
      "\n",
      "8. **Chatbots and Virtual Assistants**: Chatbots and virtual assistants could use GPT-4 to better understand and respond to user inputs that contain errors or are poorly formatted, leading to more natural and effective interactions.\n",
      "\n",
      "9. **Forensic Analysis**: In digital forensics, GPT-4 could assist in reconstructing corrupted or partially destroyed text data, aiding in investigations and data recovery efforts.\n",
      "\n",
      "10. **Gaming**: In puzzle and word games, GPT-4 could be used to generate challenging scrambled text puzzles or to provide hints to players when they are stuck.\n",
      "\n",
      "These applications demonstrate the versatility of GPT-4 and its potential to enhance various software products by improving their ability to understand and process human language, even when presented in a less-than-ideal form.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autogen.agentchat.groupchat:GroupChat select_speaker failed to resolve the next speaker's name. This is because the speaker selection OAI call returned:\n",
      "TERMINATE\n"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(manager, message=\"Find a latest paper about gpt-4 on arxiv and find its potential applications in software.\")\n",
    "# type exit to terminate the chat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
